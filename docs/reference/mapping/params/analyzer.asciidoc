[[analyzer]]
=== `analyzer`


<<mapping-index,`analyze`>> 字符串字段的值通过 <<analysis,analyzer>> 传递，将字符串转换为 _tokens_ 或 _terms_ 流。
例如，字符串 `"The quick Brown Foxes."` ，可能会根据使用的分析器分析成以下词元（tokens）：`quick` 、 `brown` 、 `fox` 。
这些是为该字段编制索引的实际词条（term），这使得可以有效地__在__大块文本搜索单个单词。

此分析过程不仅需要在索引时发生，还需要在查询时发生：查询字符串需要通过相同（或类似）的分析器传递，以便它尝试查找索引中格式相同的词条（term）。

Elasticsearch 附带了许多<<analysis-analyzers,预定义分析器>>，无需进一步配置即可使用。它还附带了许多<<analysis-charfilters,字符过滤器>>、
<< analysis-tokenizers,tokenizers>> 和 << analysis-tokenfilters >> ，它们可以组合起来为每个索引配置自定义分析器。

可以按查询，按字段或按索引指定分析器。在索引时，Elasticsearch 将按以下顺序查找分析器：

* 在映射定义的分析器。
* 为 `default` 的分析器。
* <<analysis-standard-analyzer,`standard`>> 分析器。

At query time, there are a few more layers:

* <<full-text-queries,全文搜索>>中定义的分析器。
* 映射字段中定义的 `search_analyzer` 。 
* 映射字段中定义的分析器。
* 索引设置中名为 `default_search` 的分析器。
* 索引设置中名为 `default` 的分析器。
* <<analysis-standard-analyzer,`standard`>> 分析器。

为特定字段指定分析器的最简单方法是在字段映射中定义它，如下所示：

[source,js]
--------------------------------------------------
PUT /my_index
{
  "mappings": {
    "_doc": {
      "properties": {
        "text": { <1>
          "type": "text",
          "fields": {
            "english": { <2>
              "type":     "text",
              "analyzer": "english"
            }
          }
        }
      }
    }
  }
}

GET my_index/_analyze <3>
{
  "field": "text",
  "text": "The quick Brown Foxes."
}

GET my_index/_analyze <4>
{
  "field": "text.english",
  "text": "The quick Brown Foxes."
}
--------------------------------------------------
// CONSOLE
<1> `text` 字段使用默认的 `standard` 分析器。
<2> `text.english` <<multi-fields,multi-field>> 使用 `english` 分析器，它移除停用词和应用词干。
<3> 返回词元（tokens）： [ `the`, `quick`, `brown`, `foxes` ]。
<4> 返回词元（tokens）： [ `quick`, `brown`, `fox` ]。


[[search-quote-analyzer]]
==== `search_quote_analyzer`

`search_quote_analyzer` 设置允许你为短语指定分析器，这在处理禁用短语查询的停用词时特别有用。

要禁用短语的停用词，需要使用三个分析器设置的字段：

1. 需要索引的所有词条（包括停用词）的分析器设置。
2. 用于非短语查询的 `search_analyzer` 设置，用于移除停用词。
3. 用于短语查询的 `search_quote_analyzer` 设置，不会移除停用词。

[source,js]
--------------------------------------------------
PUT my_index
{
   "settings":{
      "analysis":{
         "analyzer":{
            "my_analyzer":{ <1>
               "type":"custom",
               "tokenizer":"standard",
               "filter":[
                  "lowercase"
               ]
            },
            "my_stop_analyzer":{ <2>
               "type":"custom",
               "tokenizer":"standard",
               "filter":[
                  "lowercase",
                  "english_stop"
               ]
            }
         },
         "filter":{
            "english_stop":{
               "type":"stop",
               "stopwords":"_english_"
            }
         }
      }
   },
   "mappings":{
      "_doc":{
         "properties":{
            "title": {
               "type":"text",
               "analyzer":"my_analyzer", <3>
               "search_analyzer":"my_stop_analyzer", <4>
               "search_quote_analyzer":"my_analyzer" <5>
            }
         }
      }
   }
}

PUT my_index/_doc/1
{
   "title":"The Quick Brown Fox"
}

PUT my_index/_doc/2
{
   "title":"A Quick Brown Fox"
}

GET my_index/_search
{
   "query":{
      "query_string":{
         "query":"\"the quick brown fox\"" <6>
      }
   }
}
--------------------------------------------------
// CONSOLE
<1> `my_analyzer` 分析器，它包括所有词条，包括停用词。
<2> `my_stop_analyzer` 分析器，它移除了停用词。
<3> `analyzer` 设置指向将在索引时使用的 `my_analyzer` 分析器。
<4> `search_analyzer` 设置指向 `my_stop_analyzer` 并移除非短语查询的停用词。
<5> `search_quote_analyzer` 设置指向 `my_analyzer` 分析器并确保不从短语查询中移除停用词。
<6> 由于查询被包装在引号中，因此它被检测为短语查询，因此 `search_quote_analyzer' 启动并确保不从查询中删除停用词。
然后， `my_analyzer` 分析器将返回以下标记[`the`, `quick`, `brown`, `fox`]，这将匹配其中一个文档。
同时，将使用 `my_stop_analyzer` 分析器分析术语查询，该分析器将过滤掉停用词。因此，搜索 `The quick brown fox` 或 `A quick brown fox` 将返回两个文档，因为这两个文件都包含以下词元：[`quick`, `brown`, `fox`]。
如果没有 `search_quote_analyzer` ，则无法对短语查询进行精确匹配，因为短语查询中的停用词将被删除，从而导致两个文档匹配。
