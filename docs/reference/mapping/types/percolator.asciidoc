[[percolator]]
=== 渗透器类型

渗透器（ `percolator` ）字段类型将 json 结构解析为原生查询，并存储该查询，以便<<query-dsl-percolate-query,渗透查询>>可以使用它匹配提供的文档。

包含 json 对象的任何字段都可以配置为渗透器字段。渗透器字段类型没有设置。
只需配置渗透器字段类型就足以指示 Elasticsearch 将字段视为查询。

如果以下映射为 `query` 字段配置 `percolator` 字段类型：

[source,js]
--------------------------------------------------
PUT my_index
{
    "mappings": {
        "_doc": {
            "properties": {
                "query": {
                    "type": "percolator"
                },
                "field": {
                    "type": "text"
                }
            }
        }
    }
}
--------------------------------------------------
// CONSOLE
// TESTSETUP

然后你可以索引一个查询：

[source,js]
--------------------------------------------------
PUT my_index/_doc/match_value
{
    "query" : {
        "match" : {
            "field" : "value"
        }
    }
}
--------------------------------------------------
// CONSOLE

[IMPORTANT]
=====================================

在渗透器查询中引用的字段必须 *已经* 存在于与用于渗透的索引相关联的映射中。
为了确保这些字段存在，通过<<indices-create-index,创建索引>>或<<indices-put-mapping,放置映射>> API 添加或更新映射。
在渗透器查询中引用的字段可以存在于包含渗透器字段类型的任何类型的索引中。

=====================================

[float]
==== 重新索引你的渗透器查询

有时候，重新索引渗透器查询才能从新版本中对渗透器字段类型所做的改进中受益。

可以使用 <<docs-reindex,reindex api>> 重新索引渗透器查询。让我们看看下面的一个带有渗透器字段类型的索引吧：

[source,js]
--------------------------------------------------
PUT index
{
  "mappings": {
    "_doc" : {
      "properties": {
        "query" : {
          "type" : "percolator"
        },
        "body" : {
          "type": "text"
        }
      }
    }
  }
}

POST _aliases
{
  "actions": [
    {
      "add": {
        "index": "index",
        "alias": "queries" <1>
      }
    }
  ]
}

PUT queries/_doc/1?refresh
{
  "query" : {
    "match" : {
      "body" : "quick brown fox"
    }
  }
}
--------------------------------------------------
// CONSOLE
// TEST[continued]

<1> 始终建议为索引定义别名，以便在重新索引系统/应用程序时不需要更改就可以知道渗透器查询现在位于不同的索引中。

假设你要升级到新的主要版本，并且为了使新的 Elasticsearch 版本仍然能够读取你的查询，
那么你需要将查询重新索引到当前 Elasticsearch 版本的新索引中：

[source,js]
--------------------------------------------------
PUT new_index
{
  "mappings": {
    "_doc" : {
      "properties": {
        "query" : {
          "type" : "percolator"
        },
        "body" : {
          "type": "text"
        }
      }
    }
  }
}

POST /_reindex?refresh
{
  "source": {
    "index": "index"
  },
  "dest": {
    "index": "new_index"
  }
}

POST _aliases
{
  "actions": [ <1>
    {
      "remove": {
        "index" : "index",
        "alias": "queries"
      }
    },
    {
      "add": {
        "index": "new_index",
        "alias": "queries"
      }
    }
  ]
}
--------------------------------------------------
// CONSOLE
// TEST[continued]

<1> 如果你有一个别名，别忘记将它指向有一个新索引。

通过 `queries` 别名执行 `percolate` 查询：

[source,js]
--------------------------------------------------
GET /queries/_search
{
  "query": {
    "percolate" : {
      "field" : "query",
      "document" : {
        "body" : "fox jumps over the lazy dog"
      }
    }
  }
}
--------------------------------------------------
// CONSOLE
// TEST[continued]

现在返回来自新索引的匹配结果：

[source,js]
--------------------------------------------------
{
  "took": 3,
  "timed_out": false,
  "_shards": {
    "total": 5,
    "successful": 5,
    "skipped" : 0,
    "failed": 0
  },
  "hits": {
    "total": 1,
    "max_score": 0.2876821,
    "hits": [
      {
        "_index": "new_index", <1>
        "_type": "_doc",
        "_id": "1",
        "_score": 0.2876821,
        "_source": {
          "query": {
            "match": {
              "body": "quick brown fox"
            }
          }
        },
        "fields" : {
          "_percolator_document_slot" : [0]
        }
      }
    ]
  }
}
--------------------------------------------------
// TESTRESPONSE[s/"took": 3,/"took": "$body.took",/]

<1> 现在正在从新索引中呈现渗透器查询命中。

[float]
==== 优化查询时间文本分析

当渗透器验证渗透器候选匹配时，它将进行解析，执行查询时间文本分析并实际对正在渗透的文档运行渗透器查询。这是针对每个候选匹配以及每次执行 `percolate` 查询时完成的。
如果你的查询时间文本分析是查询解析的相对昂贵的一部分，那么文本分析可能成为渗透时花费的主要因素。当渗透器最终验证许多候选渗透器查询匹配时，该查询解析开销可能变得明显。

避免在渗透时间进行最昂贵的文本分析。在索引渗透器查询时，可以选择进行昂贵的文本分析。
这需要使用两个不同的分析仪。第一个分析器实际执行需要执行的文本分析（昂贵的部分）。
第二个分析器（通常是空白分析器）只是分割第一个分析仪产生的生成的词元（ `token` ）。
然后在索引渗透器查询之前，应该使用分析 api 来使用更昂贵的分析器来分析查询文本。

分析 api 的结果（词元 `token` ）应该用于替换渗透器查询中的原始查询文本。现在应该将查询配置为从映射和第二个分析器覆盖分析器，这一点很重要。
大多数基于文本的查询都支持 `analyzer` 选项（ `match` ， `query_string` ， `simple_query_string` ）。
使用这种方法，昂贵的文本分析只执行一次而不是多次。

让我们通过简化的例子演示这个工作流程。

假设我们想要索引以下渗透器查询：

[source,js]
--------------------------------------------------
{
  "query" : {
    "match" : {
      "body" : {
        "query" : "missing bicycles"
      }
    }
  }
}
--------------------------------------------------
// NOTCONSOLE

使用这些设置和映射：

[source,js]
--------------------------------------------------
PUT /test_index
{
  "settings": {
    "analysis": {
      "analyzer": {
        "my_analyzer" : {
          "tokenizer": "standard",
          "filter" : ["lowercase", "porter_stem"]
        }
      }
    }
  },
  "mappings": {
    "_doc" : {
      "properties": {
        "query" : {
          "type": "percolator"
        },
        "body" : {
          "type": "text",
          "analyzer": "my_analyzer" <1>
        }
      }
    }
  }
}
--------------------------------------------------
// CONSOLE
// TEST[continued]

<1> 出于例子的目的，该分析器被认为是昂贵的。

首先，我们需要使用分析 api 在索引之前执行文本分析：

[source,js]
--------------------------------------------------
POST /test_index/_analyze
{
  "analyzer" : "my_analyzer",
  "text" : "missing bicycles"
}
--------------------------------------------------
// CONSOLE
// TEST[continued]

这产生以下响应：

[source,js]
--------------------------------------------------
{
  "tokens": [
    {
      "token": "miss",
      "start_offset": 0,
      "end_offset": 7,
      "type": "<ALPHANUM>",
      "position": 0
    },
    {
      "token": "bicycl",
      "start_offset": 8,
      "end_offset": 16,
      "type": "<ALPHANUM>",
      "position": 1
    }
  ]
}
--------------------------------------------------
// TESTRESPONSE

返回的所有 tokens 需要替换渗透器查询中的查询文本：

[source,js]
--------------------------------------------------
PUT /test_index/_doc/1?refresh
{
  "query" : {
    "match" : {
      "body" : {
        "query" : "miss bicycl",
        "analyzer" : "whitespace" <1>
      }
    }
  }
}
--------------------------------------------------
// CONSOLE
// TEST[continued]

<1> 在这里选择空白分析器很重要，否则将使用映射中定义的分析器，它会使得使用该工作流程失败。请注意，空白分析器是内置分析器，如果需要使用不同的分析器，则需要首先在索引的设置中进行配置。

应该为每个渗透器查询完成在为渗滤器流索引之前的分析 api。

在渗透时，没有任何变化，渗透查询可以正常定义：

[source,js]
--------------------------------------------------
GET /test_index/_search
{
  "query": {
    "percolate" : {
      "field" : "query",
      "document" : {
        "body" : "Bycicles are missing"
      }
    }
  }
}
--------------------------------------------------
// CONSOLE
// TEST[continued]

这会产生如下响应：

[source,js]
--------------------------------------------------
{
  "took": 6,
  "timed_out": false,
  "_shards": {
    "total": 5,
    "successful": 5,
    "skipped" : 0,
    "failed": 0
  },
  "hits": {
    "total": 1,
    "max_score": 0.2876821,
    "hits": [
      {
        "_index": "test_index",
        "_type": "_doc",
        "_id": "1",
        "_score": 0.2876821,
        "_source": {
          "query": {
            "match": {
              "body": {
                "query": "miss bicycl",
                "analyzer": "whitespace"
              }
            }
          }
        },
        "fields" : {
          "_percolator_document_slot" : [0]
        }
      }
    ]
  }
}
--------------------------------------------------
// TESTRESPONSE[s/"took": 6,/"took": "$body.took",/]

[float]
==== 优化通配符查询

通配符查询比渗透器的其他查询更昂贵，尤其是在通配符表达式很大的情况下。

对于带有前缀通配符表达式的 `wildcard` 查询或只是 `prefix` 查询，
可以使用 `edge_ngram` 词元渗透器用配置了 `edge_ngram` 词元过滤器的字段上的常规 `term` 查询替换。

使用自定义分析设置创建索引：

[source,js]
--------------------------------------------------
PUT my_queries1
{
  "settings": {
    "analysis": {
      "analyzer": {
        "wildcard_prefix": { <1>
          "type": "custom",
          "tokenizer": "standard",
          "filter": [
            "lowercase",
            "wildcard_edge_ngram"
          ]
        }
      },
      "filter": {
        "wildcard_edge_ngram": { <2>
          "type": "edge_ngram",
          "min_gram": 1,
          "max_gram": 32
        }
      }
    }
  },
  "mappings": {
    "_doc": {
      "properties": {
        "query": {
          "type": "percolator"
        },
        "my_field": {
          "type": "text",
          "fields": {
            "prefix": { <3>
              "type": "text",
              "analyzer": "wildcard_prefix",
              "search_analyzer": "standard"
            }
          }
        }
      }
    }
  }
}
--------------------------------------------------
// CONSOLE
// TEST[continued]

<1> 生成前缀词元（tokens）的分析器仅在索引时使用。
<2> 根据你的前缀搜索需求增加 `min_gram` 并减少 `max_gram` 设置。
<3> 这个多字段应该用于使用 `term` 或 `match` 查询而不是 `prefix` 或 `wildcard` 查询进行前缀搜索。

然后，不是索引以下查询：

[source,js]
--------------------------------------------------
{
  "query": {
    "wildcard": {
      "my_field": "abc*"
    }
  }
}
--------------------------------------------------
// NOTCONSOLE

而是以下查询才应该被索引：

[source,js]
--------------------------------------------------
PUT /my_queries1/_doc/1?refresh
{
  "query": {
    "term": {
      "my_field.prefix": "abc"
    }
  }
}
--------------------------------------------------
// CONSOLE
// TEST[continued]

这种方式可以比第一个查询更有效地处理第二个查询。

以下搜索请求将与先前索引的渗透器查询匹配：

[source,js]
--------------------------------------------------
GET /my_queries1/_search
{
  "query": {
    "percolate": {
      "field": "query",
      "document": {
        "my_field": "abcd"
      }
    }
  }
}
--------------------------------------------------
// CONSOLE
// TEST[continued]

[source,js]
--------------------------------------------------
{
  "took": 6,
  "timed_out": false,
  "_shards": {
    "total": 5,
    "successful": 5,
    "skipped": 0,
    "failed": 0
  },
  "hits": {
    "total": 1,
    "max_score": 0.41501677,
    "hits": [
      {
        "_index": "my_queries1",
        "_type": "_doc",
        "_id": "1",
        "_score": 0.41501677,
        "_source": {
          "query": {
            "term": {
              "my_field.prefix": "abc"
            }
          }
        },
        "fields": {
          "_percolator_document_slot": [
            0
          ]
        }
      }
    ]
  }
}
--------------------------------------------------
// TESTRESPONSE[s/"took": 6,/"took": "$body.took",/]

相同的技术也可用于加速后缀通配符搜索。在 `edge_ngram` 标记过滤器之前使用 `reverse` 标记过滤器。

[source,js]
--------------------------------------------------
PUT my_queries2
{
  "settings": {
    "analysis": {
      "analyzer": {
        "wildcard_suffix": {
          "type": "custom",
          "tokenizer": "standard",
          "filter": [
            "lowercase",
            "reverse",
            "wildcard_edge_ngram"
          ]
        },
        "wildcard_suffix_search_time": {
          "type": "custom",
          "tokenizer": "standard",
          "filter": [
            "lowercase",
            "reverse"
          ]
        }
      },
      "filter": {
        "wildcard_edge_ngram": {
          "type": "edge_ngram",
          "min_gram": 1,
          "max_gram": 32
        }
      }
    }
  },
  "mappings": {
    "_doc": {
      "properties": {
        "query": {
          "type": "percolator"
        },
        "my_field": {
          "type": "text",
          "fields": {
            "suffix": {
              "type": "text",
              "analyzer": "wildcard_suffix",
              "search_analyzer": "wildcard_suffix_search_time" <1>
            }
          }
        }
      }
    }
  }
}
--------------------------------------------------
// CONSOLE
// TEST[continued]

<1> 在搜索时也需要自定义分析器，因为否则查询项不会被反转，否则将与保留的后缀词元（token）不匹配。

然后，不是索引以下查询：

[source,js]
--------------------------------------------------
{
  "query": {
    "wildcard": {
      "my_field": "*xyz"
    }
  }
}
--------------------------------------------------
// NOTCONSOLE

而是以下查询才应该被索引：

[source,js]
--------------------------------------------------
PUT /my_queries2/_doc/2?refresh
{
  "query": {
    "match": { <1>
      "my_field.suffix": "xyz"
    }
  }
}
--------------------------------------------------
// CONSOLE
// TEST[continued]

<1> 应该使用 `match` 查询而不是 `term` 查询，因为文本分析需要反转查询术语。

以下搜索请求将与先前索引的渗透器查询匹配：

[source,js]
--------------------------------------------------
GET /my_queries2/_search
{
  "query": {
    "percolate": {
      "field": "query",
      "document": {
        "my_field": "wxyz"
      }
    }
  }
}
--------------------------------------------------
// CONSOLE
// TEST[continued]

[float]
==== 专用渗透器指数

渗透器查询可以被添加到任意索引中。相较于将渗透器查询添加到数据所在的索引中，这些查询也可以添加到专用索引中。
这样做的好处是这个专用的过滤器索引可以有自己的索引设置（例如主分片和副本分片的数量）。
你如果选择专用的渗透索引，则需要确保渗透索引上的普通索引的映射也可用。否则，可能会错误地解析渗透查询。

[float]
==== 强制将未映射的字段作为字符串处理

在某些情况下，不知道哪种渗透器查询会被注册，如果渗透器查询引用的字段不存在字段映射，则添加渗透器查询失败。
这意味着需要更新映射以使字段具有适当的设置，然后可以添加渗透器查询。但有时如果处理所有未映射的字段就足够了，就好像是默认文本字段。
在这些情况下，可以将 `index.percolator.map_unmapped_fields_as_text` 设置配置为 `true` （默认为 `false` ），
然后如果在渗透器查询中引用的字段不存在，则将其作为默认文本字段处理，以便添加渗透器查询不会失败。

[float]
==== 限制

[float]
===== Parent/child

因为渗透查询一次处理一个文档，所以它不支持针对子文档运行的查询和过滤器，例如 `has_child` 和 `has_parent` 。

[float]
===== 获取查询

在查询解析期间，有许多查询通过 get 调用获取数据。例如，使用词项查询时的 `terms` 查询，使用索引脚本时的 `template` 查询和使用预索引形状时的 `geo_shape` 。
当这些查询被 `percolator` 字段类型索引时，get 调用执行一次。因此，每次渗透查询评估这些查询时，将使用索引时间的条件，形状等。
需要注意的重要一点是，每当渗透器查询在主分片和副本分片上都被索引时，都会获取这些查询所执行的词项，
因此，如果源索引在索引时发生更改，则实际索引的词项在分片副本之间可能会有所不同。

[float]
===== 脚本查询

脚本查询中的脚本只能访问 doc 值字段。渗透查询将提供的文档索引到内存索引中。
此内存索引不支持存储字段，因此不存储 `_source` 字段和其他存储字段。
这就是为什么在脚本查询中 `_source` 和其他存储字段不可用的原因。
